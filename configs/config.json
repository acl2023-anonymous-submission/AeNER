{
    "name": "tatqa-transreas3(1e-3)-numemb-deberta-v3-25",
    "wandb_project": null,
    "data_path": "aener_data",
    "device": "cuda:0",
    "dataset": "tatqa",
    "wandb_mode": null,
    "wandb_entity": "aener",
    "add_table": true,
    "seps_in_table": true,
    "embedding_lr_mult": 3,
    "table_y_embedding_len": 31,
    "table_x_embedding_len": 11,
    "predict_scale": true,
    "answer_depended_scale_predictor": true,
    "reasoning_option": "transformer",
    "reasoning_steps": 3,
    "reasoner_transformer_lr": 0.001,
    "number_embeddins_range": [
        -6,
        15
    ],
    "gcn_diff_opt": null,
    "eval_batch_size": 32,
    "accumulated_train_batch_size": 16,
    "gradient_accumulation_steps": 1,
    "seed": 42,
    "min_epoch": 0,
    "max_epoch": 25,
    "early_stop": 0,
    "dropout": 0.1,
    "learning_rate": 0.0005,
    "bert_learning_rate": 1.5e-05,
    "weight_decay": 5e-05,
    "bert_weight_decay": 0.01,
    "log_per_updates": 100,
    "eps": 1e-06,
    "warmup": 0.06,
    "warmup_schedule": "warmup_linear",
    "grad_clipping": 1.0,
    "total_length_limit": 512,
    "question_length_limit": 46,
    "do_save_model": true,
    "postnet_transformer_layers": 0,
    "postnet_gru_layers": 2,
    "postnet_transformer_learning_rate": 1.5e-05,
    "add_postnet_layernorm": true,
    "add_postnet_table_embeddings": false,
    "hidden_size": null,
    "no_single_span": false,
    "use_heavy_postnet": true,
    "use_no_postnet": false,
    "number_value_embeddings": 10.0,
    "trainable_number_value_embeddings_grid": false,
    "number_value_embeddings_loss": null,
    "number_value_embeddings_weight": 1.0,
    "number_value_embeddings_loss_after_bert": false,
    "full_logging": false,
    "span_2d": false,
    "forced_reasoning": true,
    "encoder": "deberta-v3",
    "sep_digits": false,
    "counting_as_span": false
}
